{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5562ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode output into dummy variables\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# preprocess images via PyTorch docs\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# utils\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from json import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6afbc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(ann):\n",
    "    X_raw = []\n",
    "    y = []\n",
    "    for img_data, ann_data in zip(ann['images'], ann['annotations']):\n",
    "        assert ann_data['id'] == img_data['id']\n",
    "        y.append(ann_data['category_id'])\n",
    "        img = Image.open('decathlon-1.0/' + img_data['file_name'])\n",
    "        X_raw.append(np.array(img))\n",
    "        img.close()\n",
    "    return X_raw, y\n",
    "\n",
    "def preprocess(X_raw, transformer_fn):\n",
    "    X = []\n",
    "    for img in X_raw:\n",
    "        img_pil = Image.fromarray(img)\n",
    "        proc_img = transformer_fn(img_pil)\n",
    "        X.append(proc_img)\n",
    "    return torch.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d3c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('decathlon-1.0/annotations/vgg-flowers_train.json') as f:\n",
    "    ann_train = load(f)\n",
    "    \n",
    "with open('decathlon-1.0/annotations/vgg-flowers_val.json') as f:\n",
    "    ann_val = load(f)\n",
    "\n",
    "X_train_raw, y_train = get_raw_data(ann_train)\n",
    "X_val_raw, y_val = get_raw_data(ann_val)\n",
    "\n",
    "\n",
    "dummifyer = OneHotEncoder(sparse = False)\n",
    "dummifyer.fit(np.array(y_train).reshape(-1, 1))\n",
    "\n",
    "y_train_dummy = torch.from_numpy(dummifyer.transform(np.array(y_train).reshape(-1, 1)))\n",
    "y_val_dummy = torch.from_numpy(dummifyer.transform(np.array(y_val).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d91007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "\n",
    "# set the same value of hyperparameters (learning rate=0.001, momentum=0.9) for all the layers\n",
    "momentum = 0.9\n",
    "batch_size = 64\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess images\n",
    "transformer_fn = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "X_train = preprocess(X_train_raw, transformer_fn)\n",
    "X_val = preprocess(X_val_raw, transformer_fn)\n",
    "\n",
    "# make data loader\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train_dummy), batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val_dummy), batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3531346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# move data to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b0a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for generating a fresh ResNet\n",
    "def get_resnet_feature_extractor(num_classes):\n",
    "    resnet = resnet50(pretrained = True)\n",
    "    \n",
    "    # freeze layers\n",
    "    for params in resnet.parameters():\n",
    "        params.requires_grad = False\n",
    "    \n",
    "    # change the final fully connected layer output to the number of classes in the target dataset.\n",
    "    resnet.fc = nn.Linear(2048, num_classes)\n",
    "    resnet.fc.requires_grad = True # unfreeze top layer\n",
    "    \n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2be030d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1, 0.1, 0.01, 0.001]\n",
    "#lrs = [1]\n",
    "\n",
    "nets = [get_resnet_feature_extractor(102) for i in range(len(lrs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5236ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "def train(model, tloader, vloader, lf, optim, epochs = 10):\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for t in range(epochs):\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        model.train()\n",
    "        for i, (X_local, y_local) in enumerate(tloader):\n",
    "            \n",
    "            X_local = X_local.to(device)\n",
    "            y_local = y_local.to(device)\n",
    "\n",
    "            # Forward pass: compute predicted y by passing x to the model.\n",
    "            y_pred_local = model(X_local)\n",
    "\n",
    "            # batch loss\n",
    "            loss = lf(y_pred_local, y_local)\n",
    "            epoch_train_loss += loss.item()\n",
    "            #print(\"batch: %d/%d\\tbatch loss: %.2f\" % (i + 1, n_batches, loss.item()))\n",
    "\n",
    "            # compute gradient\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # update params\n",
    "            optim.step()\n",
    "\n",
    "        # get validation loss\n",
    "        model.eval()\n",
    "        for i, (X_local, y_local) in enumerate(vloader):\n",
    "            \n",
    "            X_local = X_local.to(device)\n",
    "            y_local = y_local.to(device)\n",
    "\n",
    "            # disable autograd\n",
    "            with torch.no_grad():\n",
    "                y_pred_local = model(X_local)\n",
    "\n",
    "                # batch loss\n",
    "                loss = lf(y_pred_local, y_local)\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        # show epoch validation loss\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "\n",
    "        print(\"\\t\\t\\t\\tEpoch: %d/%d\\tTrain loss: %.2f\\tValid loss: %.2f\" \n",
    "              % (t + 1, epochs, epoch_train_loss, epoch_val_loss))\n",
    "    \n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a583fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader, encoder):\n",
    "\n",
    "    correct = 0\n",
    "    n = 0\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for X_local, y_local in loader:\n",
    "        \n",
    "        X_local = X_local.to(device)\n",
    "        y_local = y_local.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_logits = model(X_local)\n",
    "\n",
    "            y_pred = torch.argmax(y_logits, axis = 1)\n",
    "            y_true = torch.argmax(y_local, axis = 1)\n",
    "    \n",
    "        correct += sum(y_pred == y_true).item()\n",
    "        n += len(y_true)\n",
    "    \n",
    "    model.to('cpu')\n",
    "    return correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "learning rate 1.00e+00\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "for resnet, learning_rate in zip(nets, lrs):\n",
    "    \n",
    "    print('\\n\\n' + '=' * 40 + '\\nlearning rate %.2e\\n' % learning_rate + '=' * 40)\n",
    "    \n",
    "    resnet.to(device)\n",
    "    optimizer = torch.optim.SGD(resnet.parameters(), lr = learning_rate, momentum = momentum)\n",
    "    \n",
    "    train_loss, val_loss = train(\n",
    "        model = resnet, tloader =  train_loader, vloader = val_loader, \n",
    "        lf = loss_fn, epochs = epochs, optim = optimizer)\n",
    "    \n",
    "    print('final train loss: %.3f\\tfinal val loss: %.3f' % (train_loss[-1], val_loss[-1]))\n",
    "    resnet.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracies\n",
    "\n",
    "for resnet, learning_rate in zip(nets, lrs):\n",
    "    print('\\n\\n' + '=' * 40 + '\\nlearning rate %.2e\\n' % learning_rate + '=' * 40)\n",
    "    print(\"Training Accuracy:\\t%.3f\" % accuracy(resnet, train_loader, dummifyer))\n",
    "    print(\"Validation Accuracy:\\t%.3f\" % accuracy(resnet, val_loader, dummifyer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c373f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
